# talentotech-proyecto.

# ğŸ§ª Proyecto de AutomatizaciÃ³n de Pruebas â€“ UI & API

Este repositorio contiene un proyecto de **automatizaciÃ³n de pruebas de UI y API** desarrollado en **Python**, utilizando **Pytest**, **Selenium WebDriver** y **Requests**. El sitio bajo prueba para UI es **SauceDemo**, mientras que para API se utiliza **Reqres**.

El objetivo del proyecto es demostrar buenas prÃ¡cticas de automatizaciÃ³n, una arquitectura escalable y una correcta gestiÃ³n de reportes, logs y datos de prueba.

---

## ğŸ¯ Objetivo del proyecto

* Automatizar pruebas funcionales de **UI** y **API**
* Aplicar el patrÃ³n **Page Object Model (POM)**
* Utilizar datos externos (CSV / JSON)
* Generar reportes HTML automÃ¡ticos
* Implementar logging detallado de ejecuciÃ³n
* Capturar pantallas automÃ¡ticamente en tests fallidos

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

* Python 3.x
* Pytest
* Selenium WebDriver
* Requests
* Faker
* Logging
* CSV / JSON

---

## ğŸ“ Estructura del proyecto

```
project-root/
â”‚
â”œâ”€â”€ datos/
â”‚   â”œâ”€â”€ data_login.csv
â”‚   â””â”€â”€ productos.json
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ suite.log
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ screens/
â”‚
â”œâ”€â”€ pages/
â”‚   â””â”€â”€ (Page Objects)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ ui/
â”‚   â””â”€â”€ api/
â”‚
â”œâ”€â”€ run_test.py
â”œâ”€â”€ reporte.html
â””â”€â”€ README.md
```

---

## ğŸ“Š Reportes y logs

Durante la ejecuciÃ³n de las pruebas se generan automÃ¡ticamente los siguientes artefactos:

### ğŸ“„ Reporte HTML

* Archivo: `reporte.html`
* UbicaciÃ³n: carpeta raÃ­z del proyecto
* Contenido:

  * Lista de tests ejecutados
  * Estado de cada prueba (pass / fail)
  * DuraciÃ³n de cada test
  * Capturas de pantalla de pruebas fallidas

### ğŸ§¾ Logs de ejecuciÃ³n

* Archivo: `logs/suite.log`
* Incluye informaciÃ³n detallada de:

  * Inicio y fin de ejecuciÃ³n
  * Acciones realizadas
  * Errores y excepciones

### ğŸ“¸ Capturas de pantalla

* Se generan automÃ¡ticamente cuando un test falla
* UbicaciÃ³n:

```
reports/screens/
```

---

## â–¶ï¸ EjecuciÃ³n de las pruebas

Para ejecutar todas las pruebas del proyecto, utilizar el siguiente comando:

```bash
python -m run_test.py
```

---

## âœ… Casos de prueba incluidos

### UI Testing (SauceDemo)

* Login exitoso
* Login fallido
* Login exitoso y fallido utilizando Faker
* Validaciones de la pÃ¡gina de inventario
* Validaciones de la pÃ¡gina del carrito

### API Testing (Reqres)

* GET users
* POST create user
* DELETE user
* ValidaciÃ³n de cÃ³digos de estado HTTP
* ValidaciÃ³n de estructura y contenido de respuestas JSON

---

## ğŸ“¦ Manejo de datos de prueba

Los datos de prueba se gestionan de forma externa para facilitar el mantenimiento y la escalabilidad:

* `data_login.csv`

  * Usuarios vÃ¡lidos e invÃ¡lidos para pruebas de login

* `productos.json`

  * Datos de productos utilizados para validaciones en UI

---

## ğŸ§© Arquitectura

El proyecto estÃ¡ diseÃ±ado con una arquitectura modular y escalable:

* SeparaciÃ³n clara entre tests, pages y datos
* Uso de Page Object Model para UI
* ConfiguraciÃ³n centralizada
* FÃ¡cil incorporaciÃ³n de nuevos casos de prueba

---

## ğŸ“Œ ConclusiÃ³n

Este proyecto proporciona una base sÃ³lida para la automatizaciÃ³n de pruebas de **UI y API**, siguiendo buenas prÃ¡cticas de la industria. La estructura permite escalar fÃ¡cilmente, agregar nuevos tests y mantener el cÃ³digo limpio y reutilizable.

Es ideal como proyecto de prÃ¡ctica, entrega acadÃ©mica o portfolio para roles de **QA Automation / Testing**.
